{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this assignment, I was not able to graph the fit because we are using 4 features instead of 2..\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data # take all 4 features\n",
    "y = iris.target # take all 3 species of flower\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        24\n",
      "           1       1.00      1.00      1.00        20\n",
      "           2       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n",
      "Mean accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "lin_svc = SVC(kernel='linear', gamma = 'auto').fit(X_train, y_train)\n",
    "y_pred = lin_svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "data = lin_svc.score(X_test, y_test)\n",
    "print(\"Mean accuracy: \", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial Basis Function Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        24\n",
      "           1       1.00      0.95      0.97        20\n",
      "           2       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.98        60\n",
      "   macro avg       0.98      0.98      0.98        60\n",
      "weighted avg       0.98      0.98      0.98        60\n",
      "\n",
      "Mean accuracy:  0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "rbf_svc = SVC(kernel='rbf', gamma=0.6).fit(X_train, y_train)\n",
    "y_pred = rbf_svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "data = rbf_svc.score(X_test, y_test)\n",
    "print(\"Mean accuracy: \", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        24\n",
      "           1       0.87      1.00      0.93        20\n",
      "           2       1.00      0.81      0.90        16\n",
      "\n",
      "    accuracy                           0.95        60\n",
      "   macro avg       0.96      0.94      0.94        60\n",
      "weighted avg       0.96      0.95      0.95        60\n",
      "\n",
      "Mean accuracy:  0.95\n"
     ]
    }
   ],
   "source": [
    "poly_svc = SVC(kernel='poly', gamma='auto', degree=5).fit(X_train, y_train)\n",
    "y_pred = poly_svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "data = poly_svc.score(X_test, y_test)\n",
    "print(\"Mean accuracy: \", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precomputed Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        24\n",
      "           1       1.00      1.00      1.00        20\n",
      "           2       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n",
      "Mean accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "pre_train = np.dot(X_train, X_train.T)\n",
    "pre_test = np.dot(X_test, X_train.T)\n",
    "pre_svc = SVC(kernel='precomputed', gamma='auto', random_state=0).fit(pre_train, y_train)\n",
    "y_pred = pre_svc.predict(pre_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "data = pre_svc.score(pre_test, y_test)\n",
    "print(\"Mean accuracy: \", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dicussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In thi assignment, I fitted the Iris dataset using all 3 species and all 4 features using different kernels provided by Sklearn's SVM. The kernels I used were the \"Linear Kernel\",  \"Radial Basis Function Kernel\", \"Polynomial Kernel\" and the \"Precomputed Kernel\" to see the accuracy difference between each of them.\n",
    "\n",
    "I notice that the accuracy would change with each kernel when running it over again. I also notice that some kernels are better at others for this particular Iris problem. I notice that the worst one out of the 4 is the polynomial kernel, which would most of the time have a lower accuracy than the other 3 with an accuracy of 0.95. The 2nd worst one is RBF kernel at an accuracy of 0.9833. And lastly, precomputed kernel and the linear kernel are tied at an accuracy of 1.\n",
    "\n",
    "The purpose of using different kernels is to see which one can do better against the randomness of our dataset. Even though the polynomial kernel is bad for the Iris dataset, it may be the better option in some other problems. Therefore, we use differnet kernels to see which one is the best to use for the current dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
